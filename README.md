# Golem

> Embodied AI agents that learn through experimentation.

Drop a character into a scene. Claude sees it through vision models, experiments with what's possible, remembers what works, and writes new code when needed. No predefined action lists. No hardcoded behaviors. The character discovers its own capabilities.

Golem is open source because the metaverse should not be owned by one company nor should foundational AI character systems. Instead of vendor lock-in, Golem defines an open standard for AI-to-character communication so that AI can control characters in any game engine. Golem characters learn through exploration, not pre-programming. They see their world, experiment, remember what works, and become co-contributors to the virtual worlds they inhabit.

**Bring your own AI. No vendor lock-in. Contribute to Golem's codebase.**

## Why Golem?

**Traditional AI characters (Convai, Inworld):**
- Developer defines 12 actions the character can do
- AI picks from the menu
- Character is limited to what was anticipated
- Locked into their AI, their pricing, their roadmap

**Golem:**
- Developer provides a character and a scene
- Claude explores through vision and trial-and-error
- Character discovers what's possible
- Claude writes new scripts when needed
- **You choose the AI** â€” Claude, GPT, local models, whatever comes next

As AI models improve, Golem characters automatically inherit those improvements. We're not building AIâ€”we're building the embodiment layer for whatever AI becomes.

## Core Principles

### ğŸ”“ Open Source
Golem is MIT licensed. No API keys required to get started. No per-conversation fees. Run it locally, modify it freely, deploy it anywhere.

### ğŸ”Œ Bring Your Own AI
Not locked into any AI provider. Connect Claude for advanced reasoning, GPT for conversation, a local Llama for privacy, or your own fine-tuned model. Swap backends without changing game code.

### ğŸ“¡ Standard Protocol
A simple, documented WebSocket protocol for AI-to-character communication. Implement it once in any engineâ€”Unity, Unreal, Godot, web. Any AI that speaks the protocol can control any character that implements it. No proprietary SDKs.

### ğŸ§  Learning Over Programming
Characters discover their capabilities through experimentation, not configuration. Vision models see the scene. Trial-and-error finds what works. Memory retains what's learned. Code generation creates new abilities.

## How It Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Your AI Backend                       â”‚
â”‚         Claude â€¢ GPT â€¢ Llama â€¢ Your Fine-tune           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Vision Language Model                    â”‚
â”‚                   Sees the Unity scene                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Golem Protocol (WebSocket)                  â”‚
â”‚           Standard JSON messages over WS                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Golem Runtime                         â”‚
â”‚         Unity â€¢ Unreal (soon) â€¢ Godot (soon)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Feedback Loop                          â”‚
â”‚       Did it work? â†’ Memory â†’ Pattern Recognition        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

1. **Vision** â€” AI sees the scene through vision language models
2. **Experimentation** â€” Try actions, observe results
3. **Memory** â€” Remember what works, what doesn't
4. **Pattern Recognition** â€” Generalize from experience
5. **Code Generation** â€” Write new capabilities when needed

The character learns its environment like a child learns to walkâ€”through exploration, not instruction.

## Quick Start

### 1. Clone and Open in Unity

```bash
git clone https://github.com/TreasureProject/Golem.git
```

Open the project in Unity 2022.3+.

### 2. Connect Your AI Backend

Golem connects to any AI server via WebSocket:

```
ws://localhost:5173/agents/chat/external:{agentId}
```

Your server receives scene state and sends commands. Use Claude, GPT, a local modelâ€”whatever you want.

### 3. Run

Press Play. The AI sees the scene, experiments, and learns.

## The Golem Protocol

A simple JSON-over-WebSocket protocol. Any AI that produces these messages can control any Golem-compatible character.

### Movement
```json
{
  "type": "character_action",
  "data": {
    "action": {
      "type": "moveToLocation",
      "parameters": { "location": "cafe" }
    }
  }
}
```

### Voice + Lip Sync
```json
{
  "type": "emote",
  "data": {
    "type": "voice",
    "audioBase64": "<base64-encoded-audio>"
  }
}
```

### Animations
```json
{
  "type": "emote",
  "data": {
    "type": "animated",
    "animation": { "name": "wave", "duration": 2.0 }
  }
}
```

### Facial Expressions
```json
{
  "type": "facial_expression",
  "data": {
    "expression": "happy",
    "intensity": 0.9
  }
}
```

Expressions: `happy`, `sad`, `surprised`, `angry`, `neutral`, `thinking`

### Dynamic Scripting
```json
{
  "type": "script",
  "data": {
    "code": "<C# code to execute>",
    "target": "character"
  }
}
```

The AI can write and execute new behaviors at runtimeâ€”not limited to predefined actions.

### Scene State (Runtime â†’ AI)
```json
{
  "type": "scene_state",
  "data": {
    "character": { "position": [0, 0, 5], "state": "idle" },
    "objects": [...],
    "screenshot": "<base64-encoded-image>"
  }
}
```

The AI receives visual and structured feedback to close the learning loop.

## Comparison

| | Convai/Inworld | Golem |
|---|---|---|
| **Action space** | Predefined by developer | Discovered by AI |
| **Vision** | None | Vision language models |
| **Learning** | None | Trial-and-error + memory |
| **Code generation** | None | Runtime scripting |
| **AI backend** | Locked to their API | Any (Claude, GPT, local) |
| **Protocol** | Proprietary SDK | Open WebSocket standard |
| **Pricing** | Per-API-call | Open source / free |
| **Improvement** | Their roadmap | Inherits AI advances |

## Architecture

```
Golem/
â”œâ”€â”€ Assets/
â”‚   â”œâ”€â”€ Scripts/
â”‚   â”‚   â”œâ”€â”€ Character/
â”‚   â”‚   â”‚   â”œâ”€â”€ PointClickController.cs       # NavMesh movement
â”‚   â”‚   â”‚   â”œâ”€â”€ CharacterActionController.cs  # Action routing
â”‚   â”‚   â”‚   â””â”€â”€ EmotePlayer.cs                # Voice + lip sync
â”‚   â”‚   â”œâ”€â”€ Systems/
â”‚   â”‚   â”‚   â”œâ”€â”€ Networking/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ CFConnector.cs            # WebSocket client
â”‚   â”‚   â”‚   â””â”€â”€ Camera/
â”‚   â”‚   â”‚       â””â”€â”€ CameraStateMachine.cs     # Camera control
â”‚   â”‚   â””â”€â”€ Utils/
â”‚   â”‚       â””â”€â”€ WavUtility.cs                 # Audio decoding
â”‚   â”œâ”€â”€ Plugins/
â”‚   â”‚   â””â”€â”€ SALSA LipSync/                    # Lip sync
â”‚   â””â”€â”€ Scenes/
â”‚       â””â”€â”€ Main.unity
â””â”€â”€ README.md
```

## Core Components

| Component | Purpose |
|---|---|
| `CFConnector.cs` | WebSocket client, connects to any AI backend |
| `CharacterActionController.cs` | Routes AI commands to character |
| `PointClickController.cs` | NavMesh movement + interaction states |
| `EmotePlayer.cs` | Voice playback with SALSA lip sync |

## Configuration

In the Unity Inspector, configure `CFConnector`:

| Setting | Default | Description |
|---|---|---|
| Host | `localhost:5173` | AI server address |
| Agent Id | `character` | Agent identifier |
| Use Secure | `false` | Use `wss://` |
| Query Token | â€” | Auth token |

## Debug Controls

Test actions manually while developing:

| Key | Action |
|---|---|
| `1` | Move to location |
| `2` | Sit at chair |
| `3` | Stand up |
| `4` | Examine display |
| `5` | Play arcade |
| `6` | Change camera |
| `7` | Idle |
| `Space` | Stand up |

## Contributing

We welcome contributions:
- Protocol improvements
- New runtime implementations (Unreal, Godot, web)
- AI backend adapters
- Documentation

## License

MIT â€” Use it however you want.

## Links

- [Treasure Project](https://treasure.lol)

---

*Golem is built by [Treasure](https://treasure.lol), building the future of interactive IP and AI-driven entertainment experiences.*
